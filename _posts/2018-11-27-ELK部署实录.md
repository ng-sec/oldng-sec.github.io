---
layout: post  
title: ELK部署实录
date:  2018/11/27 09:22:33
categories:  安全运营
tags: elk  soc
author: ng-sec  
---

* content  
{:toc}

## 1.前言

>近年来大数据越来越火，splunk、elk等等大数据工具非常火热。运维人员面临数据越来越多的问题。接触ELK源于公司准备建设SOC，本文主要告诉大家如何搭建elk平台、使用elk接入安全设备的日志以及x-pack的破解

- 为什么用到ELK

一般我们需要进行日志分析场景：直接在日志文件中 grep、awk 就可以获得自己想要的信息。但在规模较大的场景中，此方法效率低下，面临问题包括日志量太大如何归档、文本搜索太慢怎么办、如何多维度查询。需要集中化的日志管理，所有服务器上的日志收集汇总。常见解决思路是建立集中式日志收集系统，将所有节点上的日志统一收集，管理，访问。
一般大型系统是一个分布式部署的架构，不同的服务模块部署在不同的服务器上，问题出现时，大部分情况需要根据问题暴露的关键信息，定位到具体的服务器和服务模块，构建一套集中式日志系统，可以提高定位问题的效率。
一个完整的集中式日志系统，需要包含以下几个主要特点：
- 收集－能够采集多种来源的日志数据
- 传输－能够稳定的把日志数据传输到中央系统
- 存储－如何存储日志数据
- 分析－可以支持 UI 分析
- 警告－能够提供错误报告，监控机制
 
## 2.ELK简介
>ELK是一整套解决方案，是三个软件产品的首字母缩写，Elasticsearch，Logstash和Kibana。Elasticsearch：负责数据的检索和分析;Logstash：负责数据的收集，处理和储存;Kibana：负责可视化

### 2.1 Elasticsearch

Elasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。

### 2.2 logstash

其实它就是一个收集器而已，我们需要为它指定Input和Output（当然Input和Output可以为多个）。比如我们需要把Java代码中Log4j的日志输出到ElasticSearch中，因此这里的Input就是Log4j，而Output就是ElasticSearch。

![logstash功能](http://800wifi.com/ng-sec/1543282201560.png)

### 2.3 Kibana

Kibana是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。

### 2.4 其他插件

- filebeat
它是一个轻量级的日志收集处理工具(Agent)，Filebeat占用资源少，适合于在各个服务器上搜集日志后传输给Logstash，官方也推荐此工具。
Filebeat隶属于Beats。目前Beats包含四种工具
 - Packetbeat（搜集网络流量数据）
 - Topbeat（搜集系统、进程和文件系统级别的 CPU 和内存使用情况等数据）
 - Filebeat（搜集文件数据）
 - Winlogbeat（搜集 Windows 事件日志数据）

## 3.部署配置ELK


### 3.1.部署前规划
- 架构规划

![elk架构](http://800wifi.com/ng-sec/1543290033668.png)

- 硬件规划

|  序号   |  主机名   |  CPU   |  内存   |  硬盘   | ip |安装组件|
| --- | --- | --- | --- | --- |--- |--- |
|  1  |   ELK-1  | 4vCPU    | 16G    |  350G   | 192.168.80.161| Elasticsearch、Logstash、Kibana|
|  2  |   ELK-2  | 4vCPU    |  16G   |   350G  | 192.168.80.162 | Elasticsearch|

- 服务器OS规划（Centos 7.2）

|  挂载点  |  磁盘容量   |  
| --- | --- |
|  /   |  50G   |     |     
|   /boot  |  512M   |       
|   /swap  |  16GB   |    
|   /opt  |  50GB   |   
|   /data  |  至少200GB   |      

### 3.2 部署前环境准备（ELK-1&ELK-2）
- 主机名修改
- NTP配置

``` shell?linenums
/bin/cp -rf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
```

- 关闭防火墙 （elk-1&elk-2）

``` shell?linenums
#停止firewall
systemctl stop firewalld.service
#禁止firewall开机启动
systemctl disable firewalld.service
```

- 关闭SELINUX （elk-1&elk-2）

``` shell?linenums
# 临时关闭SELINUX
sed -i 's/^SELINUX=.*$/SELINUX=disabled/g' /etc/selinux/config
# 永久关闭SELINUX,需要修改配置文件并重启生效
vi /etc/selinux/config
将SELINUX=enforcing改为SELINUX=disabled 
```
- 修改文件限制参数	

``` shell?linenums
配置文件：/etc/security/limits.conf

* soft nofile 65536
* hard nofile 65536
* soft nproc 2048
* hard nproc 4096
```
- 调整进程数

``` shell?linenums
配置文件：/etc/security/limits.d/20-nproc.conf

*          soft    nproc     4096
root       soft    nproc     unlimited
```
- 调整虚拟内存及最大并发连接

``` shell?linenums
配置文件：/etc/sysctl.conf

vm.max_map_count=655360
fs.file-max=655360
```
- 修改yum源

``` shell?linenums
配置文件：/etc/security/limits.d/20-nproc.conf

*          soft    nproc     4096
root       soft    nproc     unlimited

```


## 3.3 安装ELK
> 这里介绍两种安装方式yum和rpm

### 3.3.1 通过yum安装
- 更改yum源

- 开始安装（一条命令搞定）

``` shell?linenums
yum install java-1.8.0-openjdk kibana logstash filebeat elasticsearch
```

#### 3.3.2 通过rpm安装

- 安装jdk（elk-1&elk-2）

``` shell?linenums
yum install -y java-1.8.0-openjdk-devel.x86_64 
```

- 安装配置elasticsearch（elk-1&elk-2）

``` shell?linenums
wget https://mirrors.tuna.tsinghua.edu.cn/elasticstack/6.x/yum/6.3.0/elasticsearch-6.3.0.rpm
# 安装
rpm -ivh elasticsearch-6.3.0.rpm
```


配置ES
主节点配置（elk-1）
配置文件 /etc/elasticsearch/elasticsearch.yml
cluster.name: ff-elk
#该elasticsearch节点的名称，如果需要建立集群，该节点名称不可重复！！！
node.name: node-1
#elasticsearch数据存储和日志的路径
path.data: /data/lib/elasticsearch
path.logs: /data/log/elasticsearch
 
#监听的IP与端口，默认为127.0.0.1:9200，如果需要监听其他IP，请手动配置。但端口一般保持默认。
network.host: 0.0.0.0
#默认情况下，elasticsearch会自动搜索同一网络中所有可用的节点，当然，节点配置的集群名称必须相同。
#如果节点存在于不同的网络或网络不可达，那么就需要手动配置以下参数，单机运行则不需要配置。
discovery.zen.ping.unicast.hosts: [“192.168.80.161", “192.168.80.162"]
 
#如果启用了集群模式，那么以下参数至关重要。
#主要是为了方式脑裂现象的发生，且必须有一半以上的节点处于可用状态，否则将导致服务崩溃。
#该数值建议的计算公式为：(master_eligible_nodes / 2) + 1
discovery.zen.minimum_master_nodes: 2
 
#设定当多少个节点介入该集群后即开始数据恢复工作
gateway.recover_after_nodes: 1
备节点配置（elk-2）

配置文件 /etc/elasticsearch/elasticsearch.yml

cluster.name: ff-elk
#该elasticsearch节点的名称，如果需要建立集群，该节点名称不可重复！！！
node.name: node-2
#elasticsearch数据存储和日志的路径
path.data: /data/lib/elasticsearch
path.logs: /data/log/elasticsearch
 
#监听的IP与端口，默认为127.0.0.1:9200，如果需要监听其他IP，请手动配置。但端口一般保持默认。
network.host: 0.0.0.0
#默认情况下，elasticsearch会自动搜索同一网络中所有可用的节点，当然，节点配置的集群名称必须相同。
#如果节点存在于不同的网络或网络不可达，那么就需要手动配置以下参数，单机运行则不需要配置。
discovery.zen.ping.unicast.hosts: [“192.168.80.161", “192.168.80.162"]
 
#如果启用了集群模式，那么以下参数至关重要。
#主要是为了方式脑裂现象的发生，且必须有一半以上的节点处于可用状态，否则将导致服务崩溃。
#该数值建议的计算公式为：(master_eligible_nodes / 2) + 1
discovery.zen.minimum_master_nodes: 2
 
#设定当多少个节点介入该集群后即开始数据恢复工作
gateway.recover_after_nodes: 1
创建目录并配置添加用户目录所属为elasticsearch（elk-1，elk-2）
mkdir -p /data/lib/elasticsearch
mkdir -p /data/log/elasticsearch
/data/lib 和/data/log的所属组和所属用户
[root@elk-2 data]# ll
总用量 24
drwxr-xr-x. 3 root root 4096 8月 6 06:40 lib
drwxr-xr-x. 3 root root 4096 8月 6 06:41 log

修改/data/lib 和/data/log及其子文件夹的所属组及所属用户为elasticsearch

[root@elk-2 data]# chown -R elasticsearch:elasticsearch /data/lib/elasticsearch
[root@elk-2 data]# chown -R elasticsearch:elasticsearch /data/log/elasticsearch

[root@elk-2 lib]# ll
总用量 4
drwxr-xr-x. 2 elasticsearch elasticsearch 4096 8月 6 06:40 elasticsearch

启动elasticsearch服务
[root@elk-1 data]# systemctl status elasticsearch
● elasticsearch.service - Elasticsearch
Loaded: loaded (/usr/lib/systemd/system/elasticsearch.service; disabled; vendor preset: disabled)
Active: active (running) since 三 2018-07-25 19:26:32 CST; 41s ago
Docs: http://www.elastic.co
Main PID: 2844 (java)
CGroup: /system.slice/elasticsearch.service
├─2844 /bin/java -Xms1g -Xmx1g -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSI...
└─2906 /usr/share/elasticsearch/modules/x-pack/x-pack-ml/platform/linux-x86_64/bin/controller
7月 25 19:26:32 elk-1 systemd[1]: Started Elasticsearch.
7月 25 19:26:32 elk-1 systemd[1]: Starting Elasticsearch...
[root@elk-1 data]# systemctl status elasticsearch
● elasticsearch.service - Elasticsearch
Loaded: loaded (/usr/lib/systemd/system/elasticsearch.service; disabled; vendor preset: disabled)
Active: active (running) since 三 2018-07-25 19:26:32 CST; 42s ago
Docs: http://www.elastic.co
Main PID: 2844 (java)
CGroup: /system.slice/elasticsearch.service
├─2844 /bin/java -Xms1g -Xmx1g -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSI...
└─2906 /usr/share/elasticsearch/modules/x-pack/x-pack-ml/platform/linux-x86_64/bin/controller

7月 25 19:26:32 elk-1 systemd[1]: Started Elasticsearch.
7月 25 19:26:32 elk-1 systemd[1]: Starting Elasticsearch...
[root@elk-1 data]# vim /etc/elasticsearch/elasticsearch.yml

设置开机自启动
[root@elk-1 ~]# systemctl enable elasticsearch
Created symlink from /etc/systemd/system/multi-user.target.wants/elasticsearch.service to /usr/lib/systemd/system/elasticsearch.service.

2.3 安装配置Kinaba（elk-1）

下载安装Kinaba
wget https://mirrors.tuna.tsinghua.edu.cn/elasticstack/6.x/yum/6.3.0/kibana-6.3.0-x86_64.rpm
rpm -ivh kibana-6.3.0-x86_64.rpm
配置Kinaba
配置文件 /etc/kibana/kibana.yml
#默认监听TCP 5601端口，如果有需要，可以改为80或其他端口
server.port: 5601 
#监听的IP，默认为localhost，我将他改为0.0.0.0，即监听所有IP
server.host: "0.0.0.0“
#Kibana服务器名称，如果有多个Kibana节点，建议修改这个参数以便识别
server.name: "elk-1“
#elasticsearch的地址,如果elasticsearch与Kibana安装在不同服务器上，需要手动指定地址
elasticsearch.url: "http://192.168.80.161:9200"
#kibana会在elasticsearch中创建一个索引用于存储kibana的设置，索引名称可以自定义。一般无需修改
kibana.index: ".kibana"
xpack.security.enabled: false
#elasticsearch请求超时阈值，如果数据量及其庞大，可适当增加该值
elasticsearch.requestTimeout: 30000
 
启动Kinaba服务
[root@elk-1 ~]# systemctl start kibana
[root@elk-1 ~]# systemctl status kibana
● kibana.service - Kibana
Loaded: loaded (/etc/systemd/system/kibana.service; disabled; vendor preset: disabled)
Active: active (running) since 三 2018-10-24 20:29:09 CST; 4s ago
Main PID: 3052 (node)
CGroup: /system.slice/kibana.service
└─3052 /usr/share/kibana/bin/../node/bin/node --no-warnings /usr/share/kibana/bin/../src/cli -c /etc/kiba...

10月 24 20:29:09 elk-1 systemd[1]: Started Kibana.
10月 24 20:29:09 elk-1 systemd[1]: Starting Kibana...

设置开机自启动
[root@elk-1 ~]# systemctl enable kibana
Created symlink from /etc/systemd/system/multi-user.target.wants/elasticsearch.service to /usr/lib/systemd/system/elasticsearch.service.

2.4安装logstash（elk-1）

下载安装logstash
 wget https://mirrors.tuna.tsinghua.edu.cn/elasticstack/6.x/yum/6.3.0/logstash-6.3.0.rpm
 rpm -ivh logstash-6.3.0.rpm
 
配置logstash
配置文件/etc/logstash/logstash.yml
#logstash数据存储路径，根据实际情况修改
path.data: /data/lib/logstash
 
#logstash动态加载的配置文件，所有自定义的输入、输出和过滤配置都放置在这个目录中并以.conf结尾
path.config: /etc/logstash/conf.d/*.conf
 
#logstash日志文件路径，根据实际情况修改
path.logs: /data/log/logstash
 
创建目录并配置添加用户目录所属为logstash（elk-1）
mkdir -p /data/lib/logstash
mkdir -p /data/log/logstash
查看/data/lib 和/data/log的所属组和所属用户

[root@elk-1 lib]# ll
总用量 0
drwxr-xr-x. 3 elasticsearch elasticsearch 18 7月 25 19:26 elasticsearch
drwxr-xr-x. 2 root root 6 10月 24 20:57 logstash

[root@elk-1 log]# ll
总用量 4
drwxr-xr-x. 2 elasticsearch elasticsearch 4096 10月 24 20:07 elasticsearch
drwxr-xr-x. 2 root root 6 10月 24 20:57 logstash

修改/data/lib/logstash 和/data/log/logstash的所属组及所属用户为logstash

[root@elk-1 logstash]# chown -R logstash:logstash /data/log/logstash/
[root@elk-1 logstash]# chown -R logstash:logstash /data/lib/logstash/

[root@elk-1 log]# ll
总用量 4
drwxr-xr-x. 2 elasticsearch elasticsearch 4096 10月 24 20:07 elasticsearch
drwxr-xr-x. 2 logstash logstash 6 10月 24 20:57 logstash
[root@elk-1 lib]# ll
总用量 0
drwxr-xr-x. 3 elasticsearch elasticsearch 18 7月 25 19:26 elasticsearch
drwxr-xr-x. 2 logstash logstash 6 10月 24 20:57 logstash

请先配置然后启动

启动logstash服务

[root@elk-1 ~]# systemctl start logstash
[root@elk-1 ~]# systemctl status logstash

设置开机自启动
[root@elk-1 ~]# systemctl enable logstash

3.安全设备配置

PA配置syslog转发至elk

参考链接：

Sophos 配置syslog转发至elk

4.Kibana配置

5.logstash配置

5.x-pack使用

5.1 x-pack破解

x-pack 备份
进入 /usr/share/elasticsearch/modules/x-pack/x-pack-core
备份x-pack-core-6.3.0.jar
[root@elk-1 x-pack-core]# mkdir -p /home/backup/x-pack
[root@elk-1 ~]# cd /usr/share/elasticsearch/modules/x-pack/x-pack-core/
[root@elk-1 x-pack-core]# cp x-pack-core-6.3.0.jar /home/backup/x-pack/

创建文件
[root@elk-1 x-pack-core]# vim LicenseVerifier.java
package org.elasticsearch.license; 
import java.nio.*; import java.util.*; 
import java.security.*; 
import org.elasticsearch.common.xcontent.*; 
import org.apache.lucene.util.*; 
import org.elasticsearch.common.io.*; 
import java.io.*; 
public class LicenseVerifier { 
    public static boolean verifyLicense(final License license, final byte[] encryptedPublicKeyData) {
        return true; 
    } 
    
    public static boolean verifyLicense(final License license)     { 
        return true; 
    } 
}
[root@elk-1 x-pack-core]# vim XPackBuild.java

package org.elasticsearch.xpack.core;
import org.elasticsearch.common.io.*;
 import java.net.*;
 import org.elasticsearch.common.*;
 import java.nio.file.*;
 import java.io.*; 
 import java.util.jar.*; 
 public class XPackBuild { 
    public static final XPackBuild CURRENT;
    private String shortHash; 
    private String date; 
    @SuppressForbidden(reason = "looks up path of xpack.jar directly") static Path getElasticsearchCodebase() { 
        final URL url = XPackBuild.class.getProtectionDomain().getCodeSource().getLocation();
        try { return PathUtils.get(url.toURI()); }
        catch (URISyntaxException bogus) { 
            throw new RuntimeException(bogus); } 
        } 
        
    XPackBuild(final String shortHash, final String date) {
            this.shortHash = shortHash; 
            this.date = date; 
            } 
            
    public String shortHash() {
        return this.shortHash;
        } 
    public String date(){ 
        return this.date; 
        }
        
    static { 
        final Path path = getElasticsearchCodebase();
        String shortHash = null; 
        String date = null;
        Label_0157: { shortHash = "Unknown"; date = "Unknown"; 
    } 
    
    CURRENT = new XPackBuild(shortHash, date); 
    }
}
将java包打包成class文件
[root@elk-1 x-pack-core]# javac -cp "/usr/share/elasticsearch/modules/x-pack/x-pack-core/x-pack-core-6.3.0.jar:/usr/share/elasticsearch/lib/lucene-core-7.3.1.jar:/usr/share/elasticsearch/lib/elasticsearch-6.3.0.jar:/usr/share/elasticsearch/lib/elasticsearch-core-6.3.0.jar" LicenseVerifier.java

[root@elk-1 x-pack-core]# javac -cp "/usr/share/elasticsearch/modules/x-pack/x-pack-core/x-pack-core-6.3.0.jar:/usr/share/elasticsearch/lib/lucene-core-7.3.1.jar:/usr/share/elasticsearch/lib/elasticsearch-6.3.0.jar:/usr/share/elasticsearch/lib/elasticsearch-core-6.3.0.jar" XPackBuild.java

替换x-pack-core-6.3.0.jar的class文件
[root@elk-1 x-pack-core]# mkdir -p org/elasticsearch/license
[root@elk-1 x-pack-core]# mv LicenseVerifier.class org/elasticsearch/license/

[root@elk-1 x-pack-core]# jar uvf x-pack-core-6.3.0.jar org/elasticsearch/license/LicenseVerifier.class
正在添加: org/elasticsearch/license/LicenseVerifier.class(输入 = 410) (输出 = 245)(压缩了 40%)

[root@elk-1 x-pack-core]# mv XPackBuild.class org/elasticsearch/xpack/core
[root@elk-1 x-pack-core]# jar uvf x-pack-core-6.3.0.jar org/elasticsearch/xpack/core/XPackBuild.class
正在添加: org/elasticsearch/xpack/core/XPackBuild.class(输入 = 1508) (输出 = 841)(压缩了 44%)

获取证书
填写：名字，姓，企业邮箱，公司名称，国家等信息

![](index_files/1540469669858-o5t.png)
获取证书参考图
打开邮箱，点击elk官方发送给你的链接

下载证书
![](index_files/1540469669831-anz.png)

将证书文件修改名称为License.jason,并修改其内容
将 "type":"basic" 替换为 "type":"platinum"    # 基础版变更为铂金版
将 "expiry_date_in_millis":1561420799999替换为 "expiry_date_in_millis":3107746200000    # 1年变为50年

使用curl替换 license(license.json指的是刚刚下载修改属性后的证书，要开启elasticsearch服务)
将license.json放在当前目录，记得在激活之前一定要重启elasticsearch服务，否则会报invalid错误
curl -H "Content-Type: application/json" -XPUT 'http://192.168.80.161:9200/_xpack/license?acknowledge=true' -d @license.json

![](index_files/1540469672367-008.png)
enter description here

若失败，修改配置文件
xpack.security.enabled: false

破解成功后改回来

xpack.security.enabled: true

xpack.security.transport.ssl.enabled: true

⑥上传后查看证书时间

curl -XGET http://192.168.80.161:9200/_license

6.elasticsearch进阶版

配置SSL并启用x-pack
[root@elk-1 bin]# cd /usr/share/elasticsearch/bin/
[root@elk-1 bin]# ./elasticsearch-certgen
[root@elk-1 bin]# ./elasticsearch-certgen

Note: The 'elasticsearch-certgen' tool has been deprecated in favour of the
'elasticsearch-certutil' tool. This command will be removed in a future
release.

This tool assists you in the generation of X.509 certificates and certificate
signing requests for use with SSL in the Elastic stack. Depending on the command
line option specified, you may be prompted for the following:

The path to the output file
The output file is a zip file containing the signed certificates and
private keys for each instance. If a Certificate Authority was generated,
the certificate and private key will also be included in the output file.
Information about each instance
An instance is any piece of the Elastic Stack that requires a SSL certificate.
Depending on your configuration, Elasticsearch, Logstash, Kibana, and Beats
may all require a certificate and private key.
The minimum required value for each instance is a name. This can simply be the
hostname, which will be used as the Common Name of the certificate. A full
distinguished name may also be used.
A filename value may be required for each instance. This is necessary when the
name would result in an invalid file or directory name. The name provided here
is used as the directory name (within the zip) and the prefix for the key and
certificate files. The filename is required if you are prompted and the name
is not displayed in the prompt.
IP addresses and DNS names are optional. Multiple values can be specified as a
comma separated string. If no IP addresses or DNS names are provided, you may
disable hostname verification in your SSL configuration.
Certificate Authority private key password
The password may be left empty if desired.
Let's get started...

Please enter the desired output file [certificate-bundle.zip]: cert.zip
Enter instance name: ff-elk
Enter name for directories and files [ff-elk]: elasticsearch
Enter IP Addresses for instance (comma-separated if more than one) []: 192.168.80.161,192.168.80.162
Enter DNS names for instance (comma-separated if more than one) []: node-1,node-2
Would you like to specify another instance? Press 'y' to continue entering instance information:
Certificates written to /usr/share/elasticsearch/bin/cert.zip

This file should be properly secured as it contains the private keys for all
instances and the certificate authority.

After unzipping the file, there will be a directory for each instance containing
the certificate and private key. Copy the certificate, key, and CA certificate
to the configuration directory of the Elastic product that they will be used for
and follow the SSL configuration instructions in the product guide.

For client applications, you may only need to copy the CA certificate and
configure the client to trust this certificate.

解压证书
[root@elk-1 bin]# mv cert.zip /tmp/cert/
[root@elk-1 bin]# cd /tmp/cert/
[root@elk-1 cert]# unzip cert.zip
Archive: cert.zip
creating: ca/
inflating: ca/ca.crt
inflating: ca/ca.key
creating: elasticsearch/
inflating: elasticsearch/elasticsearch.crt
inflating: elasticsearch/elasticsearch.key